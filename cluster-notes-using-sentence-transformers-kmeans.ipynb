{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Clustering Textual Notes Using Sentence Transformers and KMeans**\n\n## **Introduction**\n\nIn this project, we aim to group a set of textual notes based on their **semantic similarity** using **natural language processing (NLP)** techniques. By converting each sentence into a vector representation through a pre-trained transformer model, we can apply **KMeans clustering** to organize them into meaningful categories. This is useful in tasks such as topic discovery, content summarization, or automatic tagging.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## **Step-by-Step Code Explanation**\n\nThe following steps explain the techniques used in the project, including code comments for a deeper understanding of each part.\n\n### 1. Installing Required Libraries\n\n```python\n!pip install sentence-transformers scikit-learn numpy pandas\n```\n\nThis command installs the required libraries:\n\n* `sentence-transformers`: For converting text into dense vector embeddings.\n* `scikit-learn`: Contains the KMeans clustering algorithm.\n* `numpy`: For numerical computations.\n* `pandas`: For structured data handling and display.\n","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers scikit-learn numpy pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:33.736586Z","iopub.execute_input":"2025-05-20T13:56:33.736920Z","iopub.status.idle":"2025-05-20T13:56:38.505279Z","shell.execute_reply.started":"2025-05-20T13:56:33.736894Z","shell.execute_reply":"2025-05-20T13:56:38.503942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 2. Importing Libraries\n\n```python\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\n```\n\n* Importing the necessary modules for embedding, clustering, numerical operations, and data management.\n\n* `sentence-transformers`: For converting sentences into vectors.\n* `KMeans`: For applying the clustering algorithm.\n* `numpy`: For numerical operations.\n* `pandas`: For working with data frames.\n","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:38.507670Z","iopub.execute_input":"2025-05-20T13:56:38.507987Z","iopub.status.idle":"2025-05-20T13:56:38.514073Z","shell.execute_reply.started":"2025-05-20T13:56:38.507961Z","shell.execute_reply":"2025-05-20T13:56:38.512539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 3. Defining Input Notes\n\n```python\nnotes = [\n    \"Artificial intelligence mimics human behavior.\",\n    \"Machine learning requires data for model training.\",\n    \"Privacy is a major ethical concern in AI.\",\n    \"Decision trees are a supervised learning method.\",\n    \"Unsupervised learning finds patterns in data.\",\n    \"Deep learning uses layered neural networks.\",\n    \"GPT models process natural language.\",\n    \"Ethical issues in AI are widely debated.\",\n    \"Bias in AI can have societal impacts.\"\n]\n```\n\n* A list of 9 short English sentences related to AI and machine learning.\n* These will be the input to our model for semantic grouping.","metadata":{}},{"cell_type":"code","source":"notes = [\n    \"Artificial intelligence mimics human behavior.\",\n    \"Machine learning requires data for model training.\",\n    \"Privacy is a major ethical concern in AI.\",\n    \"Decision trees are a supervised learning method.\",\n    \"Unsupervised learning finds patterns in data.\",\n    \"Deep learning uses layered neural networks.\",\n    \"GPT models process natural language.\",\n    \"Ethical issues in AI are widely debated.\",\n    \"Bias in AI can have societal impacts.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:38.514876Z","iopub.execute_input":"2025-05-20T13:56:38.515154Z","iopub.status.idle":"2025-05-20T13:56:38.541714Z","shell.execute_reply.started":"2025-05-20T13:56:38.515133Z","shell.execute_reply":"2025-05-20T13:56:38.540360Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"----\n\n### 4. Converting Notes to Sentence Embeddings\n\n```python\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Load a small, efficient pre-trained transformer model\nembeddings = model.encode(notes)                # Convert all sentences into vector representations\n```\n\n* Each sentence is transformed into a high-dimensional numeric vector that captures its meaning.\n* This is the foundation for semantic comparison between sentences.\n\n","metadata":{}},{"cell_type":"code","source":"model = SentenceTransformer(\"all-MiniLM-L6-v2\")\nembeddings = model.encode(notes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:38.543969Z","iopub.execute_input":"2025-05-20T13:56:38.544295Z","iopub.status.idle":"2025-05-20T13:56:41.210435Z","shell.execute_reply.started":"2025-05-20T13:56:38.544268Z","shell.execute_reply":"2025-05-20T13:56:41.209247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 5. Applying KMeans Clustering\n\n```python\nn_clusters = 3                                       # Set the number of clusters (groups) we want\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)  # Initialize KMeans with a fixed seed for reproducibility\nlabels = kmeans.fit_predict(embeddings)              # Assign each sentence to a cluster based on its vector\n```\n\n* `KMeans` tries to group similar vectors by minimizing distance within each group.\n* The `labels` array tells us which sentence belongs to which cluster.","metadata":{}},{"cell_type":"code","source":"n_clusters = 3\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nlabels = kmeans.fit_predict(embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:41.211743Z","iopub.execute_input":"2025-05-20T13:56:41.212134Z","iopub.status.idle":"2025-05-20T13:56:41.345951Z","shell.execute_reply.started":"2025-05-20T13:56:41.212097Z","shell.execute_reply":"2025-05-20T13:56:41.344719Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 6. Displaying Clustered Notes\n\n```python\ndf = pd.DataFrame({'Note': notes, 'Group': labels})  # Create a DataFrame pairing each note with its group\nprint(\"\\n--- Grouped Notes ---\")\nfor group_id in range(n_clusters):                   # Loop through each group\n    print(f\"\\n Group {group_id+1}:\")\n    group_notes = df[df['Group'] == group_id]['Note'].tolist()  # Get notes belonging to the current group\n    for note in group_notes:\n        print(f\" - {note}\")\n```\n\n* This section creates a clear printed output showing which notes fall under which group.\n* Helpful for visually evaluating the effectiveness of the clustering.\n","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({'Note': notes, 'Group': labels})\nprint(\"\\n--- Grouped Notes ---\")\nfor group_id in range(n_clusters):\n    print(f\"\\n Group {group_id+1}:\")\n    group_notes = df[df['Group'] == group_id]['Note'].tolist()\n    for note in group_notes:\n        print(f\" - {note}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:41.346955Z","iopub.execute_input":"2025-05-20T13:56:41.347227Z","iopub.status.idle":"2025-05-20T13:56:41.359928Z","shell.execute_reply.started":"2025-05-20T13:56:41.347203Z","shell.execute_reply":"2025-05-20T13:56:41.358882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n### 7. Automatic Group Title Suggestions\n\n```python\nprint(\"\\n--- Automatic Group Title Suggestions ---\")\nfor group_id in range(n_clusters):                                      # Loop through each group\n    group_indices = np.where(labels == group_id)[0]                     # Find the indices of notes in this group\n    center_vector = kmeans.cluster_centers_[group_id]                   # Get the center vector of the current cluster\n    group_vectors = embeddings[group_indices]                           # Get the vectors of notes in this group\n    closest_idx = np.argmin(np.linalg.norm(group_vectors - center_vector, axis=1))  # Find the vector closest to the center\n    title = notes[group_indices[closest_idx]]                           # Use the closest note as the group title\n    print(f\" Group {group_id+1} Title: {title}\")\n```\n\n* The goal here is to **suggest a representative title** for each cluster.\n* The sentence whose embedding is **closest to the cluster center** is used as a title.\n* This helps in understanding what each group is primarily about.\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Automatic Group Title Suggestions ---\")\nfor group_id in range(n_clusters):\n    group_indices = np.where(labels == group_id)[0]\n    center_vector = kmeans.cluster_centers_[group_id]\n    group_vectors = embeddings[group_indices]\n    closest_idx = np.argmin(np.linalg.norm(group_vectors - center_vector, axis=1))\n    title = notes[group_indices[closest_idx]]\n    print(f\" Group {group_id+1} Title: {title}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:56:41.361043Z","iopub.execute_input":"2025-05-20T13:56:41.361334Z","iopub.status.idle":"2025-05-20T13:56:41.381030Z","shell.execute_reply.started":"2025-05-20T13:56:41.361309Z","shell.execute_reply":"2025-05-20T13:56:41.379896Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Conclusion**\n\nThis project demonstrates how to combine **pre-trained language models** and **unsupervised learning** to semantically cluster text. The SentenceTransformer model accurately embedded the meaning of each sentence into numerical vectors. KMeans clustering then effectively grouped similar sentences together. Finally, we automatically suggested a meaningful title for each group based on the most representative sentence. This pipeline can be extended for large-scale text organization tasks in areas like **document management**, **topic modeling**, and **AI content moderation**.","metadata":{}}]}